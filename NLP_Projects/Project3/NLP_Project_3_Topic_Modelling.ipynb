{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import spacy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('scraped_articles_train.csv', error_bad_lines=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Watch Latest News Videos</td>\n",
       "      <td>india\\n\\nCheck out the latest news videos from...</td>\n",
       "      <td>https://timesofindia.indiatimes.com/world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Hindi TV News: Check Latest News on Hindi TV S...</td>\n",
       "      <td>Vijayendra: Need to know what happened to Sushant</td>\n",
       "      <td>http://photogallery.indiatimes.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Internet platforms can’t be allowed to monetis...</td>\n",
       "      <td>Netflix’s new documentary, ‘The Social Dilemma...</td>\n",
       "      <td>https://timesofindia.indiatimes.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Rework Special Marriage Act for love and liber...</td>\n",
       "      <td>Sometime in 2014, responding to all the rhetor...</td>\n",
       "      <td>https://timesofindia.indiatimes.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Five winners of the post-pandemic global econo...</td>\n",
       "      <td>Even as Covid-19 continues to bubble up in hot...</td>\n",
       "      <td>https://timesofindia.indiatimes.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>298</td>\n",
       "      <td>Venezuelan health workers are getting cash bon...</td>\n",
       "      <td>(CNN) Venezuela's frontline health workers are...</td>\n",
       "      <td>https://edition.cnn.com/americas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299</td>\n",
       "      <td>299</td>\n",
       "      <td>30 cases of Covid-19 have been linked to a kar...</td>\n",
       "      <td>(CNN) A Canadian karaoke bar could face fines ...</td>\n",
       "      <td>https://edition.cnn.com/americas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>Amazon tribes are using drones to track defore...</td>\n",
       "      <td>The 28-year-old belongs to a 250-strong tribe ...</td>\n",
       "      <td>https://edition.cnn.com/americas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>301</td>\n",
       "      <td>301</td>\n",
       "      <td>Amazon tribes are using technology to protect ...</td>\n",
       "      <td>Mandu Uru Eu Wau Wau is a member of the Uru-Eu...</td>\n",
       "      <td>https://edition.cnn.com/americas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>302</td>\n",
       "      <td>302</td>\n",
       "      <td>With Canada and Mexico borders closed, America...</td>\n",
       "      <td>(CNN) \"Want to hear the joke about insulin?\" g...</td>\n",
       "      <td>https://edition.cnn.com/americas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                              Title  \\\n",
       "0             0                           Watch Latest News Videos   \n",
       "1             1  Hindi TV News: Check Latest News on Hindi TV S...   \n",
       "2             2  Internet platforms can’t be allowed to monetis...   \n",
       "3             3  Rework Special Marriage Act for love and liber...   \n",
       "4             4  Five winners of the post-pandemic global econo...   \n",
       "..          ...                                                ...   \n",
       "298         298  Venezuelan health workers are getting cash bon...   \n",
       "299         299  30 cases of Covid-19 have been linked to a kar...   \n",
       "300         300  Amazon tribes are using drones to track defore...   \n",
       "301         301  Amazon tribes are using technology to protect ...   \n",
       "302         302  With Canada and Mexico borders closed, America...   \n",
       "\n",
       "                                                  Text  \\\n",
       "0    india\\n\\nCheck out the latest news videos from...   \n",
       "1    Vijayendra: Need to know what happened to Sushant   \n",
       "2    Netflix’s new documentary, ‘The Social Dilemma...   \n",
       "3    Sometime in 2014, responding to all the rhetor...   \n",
       "4    Even as Covid-19 continues to bubble up in hot...   \n",
       "..                                                 ...   \n",
       "298  (CNN) Venezuela's frontline health workers are...   \n",
       "299  (CNN) A Canadian karaoke bar could face fines ...   \n",
       "300  The 28-year-old belongs to a 250-strong tribe ...   \n",
       "301  Mandu Uru Eu Wau Wau is a member of the Uru-Eu...   \n",
       "302  (CNN) \"Want to hear the joke about insulin?\" g...   \n",
       "\n",
       "                                        Source  \n",
       "0    https://timesofindia.indiatimes.com/world  \n",
       "1           http://photogallery.indiatimes.com  \n",
       "2          https://timesofindia.indiatimes.com  \n",
       "3          https://timesofindia.indiatimes.com  \n",
       "4          https://timesofindia.indiatimes.com  \n",
       "..                                         ...  \n",
       "298           https://edition.cnn.com/americas  \n",
       "299           https://edition.cnn.com/americas  \n",
       "300           https://edition.cnn.com/americas  \n",
       "301           https://edition.cnn.com/americas  \n",
       "302           https://edition.cnn.com/americas  \n",
       "\n",
       "[303 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Watch Latest News Videos</td>\n",
       "      <td>india\\n\\nCheck out the latest news videos from...</td>\n",
       "      <td>https://timesofindia.indiatimes.com/world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Hindi TV News: Check Latest News on Hindi TV S...</td>\n",
       "      <td>Vijayendra: Need to know what happened to Sushant</td>\n",
       "      <td>http://photogallery.indiatimes.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Internet platforms can’t be allowed to monetis...</td>\n",
       "      <td>Netflix’s new documentary, ‘The Social Dilemma...</td>\n",
       "      <td>https://timesofindia.indiatimes.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Rework Special Marriage Act for love and liber...</td>\n",
       "      <td>Sometime in 2014, responding to all the rhetor...</td>\n",
       "      <td>https://timesofindia.indiatimes.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Five winners of the post-pandemic global econo...</td>\n",
       "      <td>Even as Covid-19 continues to bubble up in hot...</td>\n",
       "      <td>https://timesofindia.indiatimes.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                           Watch Latest News Videos   \n",
       "1  Hindi TV News: Check Latest News on Hindi TV S...   \n",
       "2  Internet platforms can’t be allowed to monetis...   \n",
       "3  Rework Special Marriage Act for love and liber...   \n",
       "4  Five winners of the post-pandemic global econo...   \n",
       "\n",
       "                                                Text  \\\n",
       "0  india\\n\\nCheck out the latest news videos from...   \n",
       "1  Vijayendra: Need to know what happened to Sushant   \n",
       "2  Netflix’s new documentary, ‘The Social Dilemma...   \n",
       "3  Sometime in 2014, responding to all the rhetor...   \n",
       "4  Even as Covid-19 continues to bubble up in hot...   \n",
       "\n",
       "                                      Source  \n",
       "0  https://timesofindia.indiatimes.com/world  \n",
       "1         http://photogallery.indiatimes.com  \n",
       "2        https://timesofindia.indiatimes.com  \n",
       "3        https://timesofindia.indiatimes.com  \n",
       "4        https://timesofindia.indiatimes.com  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(data.columns[data.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Netflix’s new documentary, ‘The Social Dilemma’, should be compulsory viewing for Indians. It helps explain the unprecedented spread of hate speech and communal falsehoods. It features executives and IT nerds from top internet companies — Facebook, Twitter, Instagram, Google, YouTube. They say they started by believing that the internet would be a great democratiser, providing voice and knowledge to millions lacking it. Alas, it is also producing terrible polarisation, lies and strife.\\n\\nThis is not because internet companies have bad people or evil intentions. The problem lies in their profit model. They offer great free services. Their profits come from advertising, often subliminal advertising. This means flashing messages for very brief periods below the normal human perception level, reaching the subconscious. Subliminal advertising has long been used by conventional advertisers too, highlighted in books like Vance Packard’s ‘The Hidden Persuaders’. But the smartphone has taken this psychological manipulation to new heights.\\n\\nFree internet programmes aim to get the attention of as many viewers as possible for as long as possible. They take advantage of the high addictiveness of the net, especially for youngsters. The companies employ algorithms, complex software programmes, to track and analyse every move of viewers, getting to know more about their likes and tendencies than a psychiatrist. Using this psychological knowledge, the algorithms feed viewers with ads and messages that will hook their attention — not just to buy things but use news, videos and other devices that guide viewers into groups with similar likes and dislikes. The algorithms even feed different versions of the same news to different groups to satisfy their psychological needs, deepening polarisation.\\n\\nAlgorithms are driving people into warring camps\\n\\nThe companies seek to link viewers with other viewers as fast as possible to create networks of millions. Advertisers find that the algorithms can help them target the very people and groups most likely to buy their goods and services, at a very low cost per viewer. So, advertising has shifted hugely to the net, making billions for network owners.\\n\\nControl over the data of viewers has given the companies unprecedented power to influence viewers and make money. Data, it is said, is the new oil. This has raised troubling questions about privacy and security. Many governments now seek to protect data generated in their borders for security reasons. Others are considering proposals to make the companies for the use of viewer data.\\n\\nBut more sinister is the way the networks harness the dark side of human nature to promote polarised groups with a contempt for rival groups that incites hate and violence. The net creates groups of individuals listening only to one another, brimming with dangerous passion.\\n\\nWithin each group, falsehoods and fake news about other groups spread with lightning speed and attempts to tell the truth are dismissed as conspiracies. The IT nerds say that falsehoods spread six times faster and wider than truths, Falsehoods titillate and get lots of viewers, while the truth is mundane and unexciting. The end result of this polarisation, say the nerds, could be violent clashes and even civil war.\\n\\nThe documentary is concerned mainly with the US, which has recently witnessed unprecedented polarisation, fake news and hate speech. This has been blamed on President Trump but should be blamed as much on the algorithms that drive evermore people into warring camps.\\n\\nIn India, the BJP is blamed for communal polarisation for electoral advantage. But that same polarisation is being driven quite independently by internet companies offering free services poisoned with hate. This fortifies the extreme fringes of both Hinduism and Islam, driving India towards Hindu-Muslim militancy.\\n\\nForget the pleas of Facebook or Google that they are mere platforms where people meet. They make their money by using algorithms as psychological tools to promote advertising to communities tailor-made for divisiveness. They did not intend the dark side of their business but will not change their strategy because massive profits flow out of it.\\n\\nRecently Facebook and Twitter have been pressured by the public and advertisers to remove or label hate posts on their sites. I initially supported this move. But I now realise that this does nothing to stop the algorithms that create divisiveness and hate — and profits.\\n\\nWe need a high-powered technical committee full of nerds to find ways to check this. Government regulation is increasing for national security and privacy. But the prime need is regulation to stop the monetisation of hate by internet companies. This may require a new set of counter-algorithms. Pessimists say the genie is out of the bottle and cannot be put back. Nevertheless, we must try. The nerds who contributed to the problem need to contribute to the solution.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['Title','Text']].dropna()\n",
    "#articles is a list of all articles\n",
    "articles = data['Text'].tolist()\n",
    "articles[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import nltk\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def clean_text(document):\n",
    "    document = re.sub('[^\\w_\\s-]', ' ',document)       #remove punctuation marks and other symbols\n",
    "    tokens = nltk.word_tokenize(document)              #Tokenize sentences\n",
    "    cleaned_article = ' '.join([stemmer.stem(item) for item in tokens])    #Stemming each token\n",
    "    return cleaned_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'netflix s new documentari the social dilemma should be compulsori view for indian it help explain the unpreced spread of hate speech and communal falsehood it featur execut and it nerd from top internet compani facebook twitter instagram googl youtub they say they start by believ that the internet would be a great democratis provid voic and knowledg to million lack it ala it is also produc terribl polaris lie and strife this is not becaus internet compani have bad peopl or evil intent the problem lie in their profit model they offer great free servic their profit come from advertis often sublimin advertis this mean flash messag for veri brief period below the normal human percept level reach the subconsci sublimin advertis has long been use by convent advertis too highlight in book like vanc packard s the hidden persuad but the smartphon has taken this psycholog manipul to new height free internet programm aim to get the attent of as mani viewer as possibl for as long as possibl they take advantag of the high addict of the net especi for youngster the compani employ algorithm complex softwar programm to track and analys everi move of viewer get to know more about their like and tendenc than a psychiatrist use this psycholog knowledg the algorithm feed viewer with ad and messag that will hook their attent not just to buy thing but use news video and other devic that guid viewer into group with similar like and dislik the algorithm even feed differ version of the same news to differ group to satisfi their psycholog need deepen polaris algorithm are drive peopl into war camp the compani seek to link viewer with other viewer as fast as possibl to creat network of million advertis find that the algorithm can help them target the veri peopl and group most like to buy their good and servic at a veri low cost per viewer so advertis has shift huge to the net make billion for network owner control over the data of viewer has given the compani unpreced power to influenc viewer and make money data it is said is the new oil this has rais troubl question about privaci and secur mani govern now seek to protect data generat in their border for secur reason other are consid propos to make the compani for the use of viewer data but more sinist is the way the network har the dark side of human natur to promot polaris group with a contempt for rival group that incit hate and violenc the net creat group of individu listen onli to one anoth brim with danger passion within each group falsehood and fake news about other group spread with lightn speed and attempt to tell the truth are dismiss as conspiraci the it nerd say that falsehood spread six time faster and wider than truth falsehood titil and get lot of viewer while the truth is mundan and unexcit the end result of this polaris say the nerd could be violent clash and even civil war the documentari is concern main with the us which has recent wit unpreced polaris fake news and hate speech this has been blame on presid trump but should be blame as much on the algorithm that drive evermor peopl into war camp in india the bjp is blame for communal polaris for elector advantag but that same polaris is be driven quit independ by internet compani offer free servic poison with hate this fortifi the extrem fring of both hinduism and islam drive india toward hindu-muslim milit forget the plea of facebook or googl that they are mere platform where peopl meet they make their money by use algorithm as psycholog tool to promot advertis to communiti tailor-mad for divis they did not intend the dark side of their busi but will not chang their strategi becaus massiv profit flow out of it recent facebook and twitter have been pressur by the public and advertis to remov or label hate post on their site i initi support this move but i now realis that this doe noth to stop the algorithm that creat divis and hate and profit we need a high-pow technic committe full of nerd to find way to check this govern regul is increas for nation secur and privaci but the prime need is regul to stop the monetis of hate by internet compani this may requir a new set of counter-algorithm pessimist say the geni is out of the bottl and can not be put back nevertheless we must tri the nerd who contribut to the problem need to contribut to the solut'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaned, tokenized and stemmed article\n",
    "cleaned_articles = list(map(clean_text, articles))\n",
    "cleaned_articles[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing function for the entire dataset\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text,pos='v'))\n",
    "\n",
    "#Tokenize and Lemmatize\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token)>3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = []\n",
    "\n",
    "for doc in cleaned_articles:\n",
    "    processed_docs.append(preprocess(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['india', 'check', 'latest', 'news', 'video', 'time', 'india', 'cover', 'wide', 'ring', 'topic', 'news', 'video', 'break', 'news', 'polit', 'news', 'polit', 'debat', 'current', 'affair', 'news', 'busi', 'news', 'world', 'news', 'scienc', 'news', 'educ', 'news', 'watch', 'video', 'news', 'event', 'happen', 'video', 'stori', 'world', 'on', 'stay', 'updat', 'time', 'india', 'news', 'video'], ['vijayendra', 'need', 'know', 'happen', 'sushant'], ['netflix', 'documentari', 'social', 'dilemma', 'compulsori', 'view', 'indian', 'help', 'explain', 'unprec', 'spread', 'hate', 'speech', 'communal', 'falsehood', 'featur', 'execut', 'nerd', 'internet', 'compani', 'facebook', 'twitter', 'instagram', 'googl', 'youtub', 'start', 'believ', 'internet', 'great', 'democrati', 'provid', 'voic', 'knowledg', 'million', 'lack', 'produc', 'terribl', 'polari', 'strife', 'becaus', 'internet', 'compani', 'peopl', 'evil', 'intent', 'problem', 'profit', 'model', 'offer', 'great', 'free', 'servic', 'profit', 'come', 'adverti', 'sublimin', 'adverti', 'mean', 'flash', 'messag', 'veri', 'brief', 'period', 'normal', 'human', 'percept', 'level', 'reach', 'subconsci', 'sublimin', 'adverti', 'long', 'convent', 'adverti', 'highlight', 'book', 'like', 'vanc', 'packard', 'hide', 'persuad', 'smartphon', 'take', 'psycholog', 'manipul', 'height', 'free', 'internet', 'programm', 'attent', 'mani', 'viewer', 'possibl', 'long', 'possibl', 'advantag', 'high', 'addict', 'especi', 'youngster', 'compani', 'employ', 'algorithm', 'complex', 'softwar', 'programm', 'track', 'anali', 'everi', 'viewer', 'know', 'like', 'tendenc', 'psychiatrist', 'psycholog', 'knowledg', 'algorithm', 'fee', 'viewer', 'messag', 'hook', 'attent', 'thing', 'news', 'video', 'devic', 'guid', 'viewer', 'group', 'similar', 'like', 'dislik', 'algorithm', 'fee', 'differ', 'version', 'news', 'differ', 'group', 'satisfi', 'psycholog', 'need', 'deepen', 'polari', 'algorithm', 'drive', 'peopl', 'camp', 'compani', 'seek', 'link', 'viewer', 'viewer', 'fast', 'possibl', 'creat', 'network', 'million', 'adverti', 'algorithm', 'help', 'target', 'veri', 'peopl', 'group', 'like', 'good', 'servic', 'veri', 'cost', 'viewer', 'adverti', 'shift', 'huge', 'billion', 'network', 'owner', 'control', 'data', 'viewer', 'give', 'compani', 'unprec', 'power', 'influenc', 'viewer', 'money', 'data', 'say', 'rai', 'troubl', 'question', 'privaci', 'secur', 'mani', 'govern', 'seek', 'protect', 'data', 'generat', 'border', 'secur', 'reason', 'consid', 'propo', 'compani', 'viewer', 'data', 'sinist', 'network', 'dark', 'human', 'natur', 'promot', 'polari', 'group', 'contempt', 'rival', 'group', 'incit', 'hate', 'violenc', 'creat', 'group', 'individu', 'listen', 'on', 'anoth', 'brim', 'danger', 'passion', 'group', 'falsehood', 'fake', 'news', 'group', 'spread', 'lightn', 'speed', 'attempt', 'tell', 'truth', 'dismiss', 'conspiraci', 'nerd', 'falsehood', 'spread', 'time', 'faster', 'wider', 'truth', 'falsehood', 'titil', 'viewer', 'truth', 'mundan', 'unexcit', 'result', 'polari', 'nerd', 'violent', 'clash', 'civil', 'documentari', 'concern', 'main', 'recent', 'unprec', 'polari', 'fake', 'news', 'hate', 'speech', 'blame', 'presid', 'trump', 'blame', 'algorithm', 'drive', 'evermor', 'peopl', 'camp', 'india', 'blame', 'communal', 'polari', 'elector', 'advantag', 'polari', 'drive', 'quit', 'independ', 'internet', 'compani', 'offer', 'free', 'servic', 'poison', 'hate', 'fortifi', 'extrem', 'fring', 'hinduism', 'islam', 'drive', 'india', 'hindu', 'muslim', 'milit', 'forget', 'plea', 'facebook', 'googl', 'mere', 'platform', 'peopl', 'meet', 'money', 'algorithm', 'psycholog', 'tool', 'promot', 'adverti', 'communiti', 'tailor', 'divi', 'intend', 'dark', 'busi', 'chang', 'strategi', 'becaus', 'massiv', 'profit', 'flow', 'recent', 'facebook', 'twitter', 'pressur', 'public', 'adverti', 'remov', 'label', 'hate', 'post', 'site', 'initi', 'support', 'reali', 'noth', 'stop', 'algorithm', 'creat', 'divi', 'hate', 'profit', 'need', 'high', 'technic', 'committ', 'nerd', 'check', 'govern', 'regul', 'increa', 'nation', 'secur', 'privaci', 'prime', 'need', 'regul', 'stop', 'moneti', 'hate', 'internet', 'compani', 'requir', 'counter', 'algorithm', 'pessimist', 'geni', 'bottl', 'nerd', 'contribut', 'problem', 'need', 'contribut', 'solut'], ['sometim', 'respond', 'rhetor', 'love', 'jihad', 'actor', 'saif', 'khan', 'write', 'intermarriag', 'jihad', 'intermarriag', 'india', 'romant', 'idea', 'beli', 'realiti', 'inter', 'cast', 'marriag', 'hover', 'marri', 'faith', 'transgress', 'gotra', 'rule', 'invit', 'terribl', 'violenc', 'countri', 'special', 'marriag', 'marriag', 'person', 'liber', 'individu', 'crush', 'collect', 'anyon', 'marri', 'anyon', 'choo', 'smear', 'line', 'divid', 'practic', 'requir', 'coupl', 'jump', 'extra', 'hoop', 'marri', 'outsid', 'tradit', 'communiti', 'suprem', 'court', 'hear', 'plea', 'seek', 'mandatori', 'publici', 'coupl', 'privat', 'month', 'anyon', 'obstruct', 'petit', 'point', 'squar', 'right', 'privaci', 'marri', 'notic', 'intend', 'marriag', 'pictur', 'address', 'phone', 'number', 'offic', 'wall', 'friend', 'visit', 'offic', 'send', 'pictur', 'peel', 'notic', 'near', 'year', 'event', 'mani', 'coupl', 'piec', 'paper', 'devast', 'effect', 'month', 'famili', 'communiti', 'busybodi', 'faith', 'cast', 'border', 'forc', 'harass', 'coupl', 'public', 'offici', 'conserv', 'cloth', 'special', 'marriag', 'enact', 'newli', 'free', 'nation', 'centr', 'individu', 'forg', 'common', 'citizenship', 'women', 'substant', 'right', 'nehru', 'ambedkar', 'push', 'civil', 'famili', 'want', 'step', 'outsid', 'communiti', 'resist', 'conserv', 'legisl', 'congress', 'string', 'attach', 'difficult', 'passag', 'parliament', 'anxieti', 'yearn', 'person', 'freedom', 'plain', 'movi', 'romant', 'love', 'core', 'cinemat', 'dream', 'cultur', 'scholar', 'aarti', 'wani', 'book', 'fantasi', 'modern', 'modern', 'india', 'imagin', 'subver', 'border', 'cross', 'romanc', 'audac', 'fall', 'love', 'social', 'context', 'peopl', 'option', 'special', 'marriag', 'embodi', 'ambiv', 'mani', 'condit', 'undercut', 'intent', 'apart', 'time', 'requir', 'resid', 'claus', 'hard', 'coupl', 'evad', 'unwelcom', 'attent', 'redesign', 'origin', 'enabl', 'purpo', 'mind', 'higher', 'penalti', 'rai', 'invalid', 'object', 'disciplinari', 'action', 'offici', 'social', 'bulli', 'civil', 'reason', 'coupl', 'ambit', 'hear', 'petit', 'court', 'observ', 'notic', 'period', 'parent', 'wouldn', 'know', 'whereabout', 'elop', 'offspr', 'husband', 'wouldn', 'know', 'wife', 'marri', 'anoth', 'bewild', 'statement', 'whatev', 'logic', 'patriarch', 'famili', 'adult', 'citizen', 'decid', 'marri', 'constitut', 'republ', 'parent', 'opinion', 'besid', 'point', 'address', 'fraud', 'bigami', 'notic', 'requir', 'marriag', 'person', 'marri', 'secular', 'outsid', 'canopi', 'communiti', 'arous', 'special', 'suspicion', 'time', 'interfaith', 'love', 'cast', 'love', 'jihad', 'stamp', 'hiss', 'chorus', 'oppress', 'year', 'karnataka', 'hindutva', 'activist', 'pile', 'local', 'paediatrician', 'daughter', 'marri', 'muslim', 'boyfriend', 'young', 'woman', 'shut', 'wish', 'wish', 'meri', 'marzi', 'come', 'woman', 'earthshak', 'idea', 'cultur', 'societi', 'stack', 'cast', 'religion', 'control', 'marriag', 'mate', 'essenti', 'communiti', 'seal', 'intact', 'women', 'want', 'bodi', 'live', 'happen', 'puriti', 'properti', 'lineag', 'anyon', 'claim', 'care', 'uniform', 'civil', 'code', 'good', 'faith', 'invest', 'better', 'special', 'marriag', 'love', 'liberti'], ['covid', 'continu', 'bubbl', 'spot', 'world', 'mani', 'peopl', 'economi', 'poi', 'rise', 'fail', 'principl', 'understand', 'global', 'environ', 'point', 'time', 'mean', 'understand', 'rule', 'critic', 'post', 'pandem', 'world', 'pandem', 'accel', 'broad', 'turn', 'inward', 'begin', 'global', 'financ', 'crisi', 'globali', 'alreadi', 'give', 'globali', 'cross', 'border', 'flow', 'good', 'money', 'declin', 'befor', 'pandem', 'leader', 'nation', 'biggest', 'beneficiari', 'globali', 'includ', 'china', 'india', 'begin', 'champion', 'self', 'reli', 'goal', 'recent', 'decad', 'pursu', 'main', 'isol', 'outlier', 'like', 'north', 'korea', 'govern', 'increa', 'control', 'economi', 'command', 'shutdown', 'effect', 'nationali', 'busi', 'payrol', 'unimagin', 'month', 'public', 'debt', 'budget', 'deficit', 'explod', 'mani', 'countri', 'redoubt', 'globali', 'virtual', 'economi', 'accel', 'lockdown', 'peopl', 'retreat', 'home', 'work', 'play', 'shop', 'studi', 'habit', 'form', 'habit', 'help', 'virtual', 'enterpri', 'continu', 'grow', 'rapid', 'higher', 'base', 'pandem', 'mean', 'post', 'pandem', 'world', 'rule', 'success', 'nation', 'geographi', 'trade', 'state', 'compet', 'debt', 'invest', 'greatest', 'impact', 'nation', 'success', 'strength', 'strong', 'domest', 'market', 'unusu', 'export', 'prowess', 'compet', 'govern', 'measur', 'indic', 'matter', 'right', 'case', 'death', 'million', 'covid', 'govern', 'debt', 'deficit', 'digit', 'sophist', 'includ', 'heavi', 'invest', 'research', 'develop', 'screen', 'major', 'develop', 'emerg', 'economi', 'strength', 'yield', 'fascin', 'surpri', 'list', 'notabl', 'absenc', 'econom', 'superpow', 'china', 'undermin', 'heavi', 'debt', 'doubt', 'govern', 'handl', 'pandem', 'india', 'major', 'winner', 'long', 'disappoint', 'optimist', 'pessimist', 'alik', 'tend', 'rank', 'middl', 'emerg', 'world', 'pack', 'rule', 'hasn', 'chang', 'pandem', 'india', 'come', 'largest', 'emerg', 'countri', 'post', 'pandem', 'screen', 'rank', 'categori', 'india', 'relat', 'vulner', 'forc', 'deglobali', 'thank', 'vast', 'domest', 'consum', 'market', 'india', 'score', 'govern', 'compet', 'rank', 'categori', 'death', 'case', 'million', 'peopl', 'score', 'govern', 'debt', 'deficit', 'place', 'india', 'half', 'class', 'number', 'final', 'unexpect', 'india', 'rank', 'on', 'emerg', 'world', 'digit', 'sophist', 'spend', 'bare', 'half', 'percentag', 'point', 'research', 'develop', 'land', 'number', 'world', 'digit', 'competit', 'rank', 'swiss', 'busi', 'school', 'meanwhil', 'list', 'potenti', 'post', 'pandem', 'winner', 'germani', 'lead', 'categori', 'near', 'lockdown', 'bare', 'month', 'thank', 'quick', 'respon', 'coordin', 'nation', 'local', 'govern', 'germani', 'angela', 'merkel', 'train', 'scientist', 'joust', 'washington', 'state', 'look', 'embarrass', 'contrast', 'germani', 'rare', 'countri', 'go', 'pandem', 'relat', 'level', 'debt', 'afford', 'biggest', 'domest', 'stimulus', 'packag', 'major', 'nation', 'despit', 'extend', 'offer', 'stimulus', 'fellow', 'member', 'come', 'lowest', 'public', 'debt', 'major', 'power', 'merkel', 'lead', 'effort', 'creat', 'european', 'recoveri', 'fund', 'help', 'bridg', 'contin', 'north', 'south', 'divid', 'legaci', 'sort', 'european', 'renaiss', 'finland', 'nokia', 'go', 'dodo', 'nest', 'home', 'microsoft', 'finland', 'produc', 'tech', 'giant', 'like', 'rovio', 'maker', 'angri', 'bird', 'tech', 'power', 'accord', 'compet', 'bureaucraci', 'littl', 'household', 'debt', 'manag', 'public', 'debt', 'finland', 'glare', 'vulner', 'challeng', 'post', 'pandem', 'period', 'switzerland', 'perhap', 'europ', 'streamlin', 'centrali', 'govern', 'bring', 'covid', 'death', 'rate', 'near', 'zero', 'creat', 'econom', 'relief', 'agenc', 'surpri', 'small', 'busi', 'deliv', 'support', 'loan', 'matter', 'hour', 'astonish', 'competit', 'small', 'countri', 'switzerland', 'smaller', 'popul', 'scandinavian', 'countri', 'creat', 'twice', 'mani', 'european', 'compani', 'scandinavian', 'countri', 'combin', 'swiss', 'generat', 'patent', 'person', 'world', 'invest', 'heavili', 'switzerland', 'global', 'tech', 'power', 'weak', 'household', 'mortgag', 'debt', 'vietnam', 'vietnam', 'reali', 'potenti', 'china', 'major', 'export', 'power', 'effici', 'post', 'communist', 'govern', 'vietnam', 'stun', 'success', 'contain', 'pandem', 'on', 'death', 'date', 'rest', 'world', 'turn', 'immigr', 'trade', 'vietnam', 'continu', 'open', 'sign', 'free', 'trade', 'agreement', 'decad', 'precious', 'nation', 'attract', 'invest', 'export', 'factori', 'accel', 'pace', 'rapid', 'manufactur', 'ladder', 'stitch', 'togeth', 'sneaker', 'smartphon', 'airpod', 'domest', 'economi', 'leapfrog', 'landlin', 'straight', 'mobil', 'internet', 'outsid', 'small', 'outlier', 'vietnam', 'track', 'finish', 'world', 'fastest', 'grow', 'economi', 'taiwan', 'south', 'korea', 'taiwan', 'nation', 'grow', 'rapid', 'pace', 'decad', 'rank', 'countri', 'post', 'pandem', 'factor', 'taiwan', 'spotlight', 'narrow', 'margin', 'like', 'south', 'korea', 'invest', 'heavili', 'tech', 'alreadi', 'world', 'digiti', 'countri', 'taiwan', 'slight', 'lower', 'govern', 'deficit', 'debt', 'covid', 'death', 'rate', 'million', 'lowest', 'major', 'emerg', 'develop', 'economi', 'achil', 'heel', 'relat', 'small', 'debt', 'soak', 'consum', 'economi', 'taiwan', 'consum', 'market', 'slight', 'larger', 'share', 'debt', 'ride', 'russia', 'dark', 'hor', 'russia', 'fact', 'score', 'singl', 'post', 'pandem', 'factor', 'list', 'larg', 'becaus', 'turn', 'financ', 'fortress', 'impervi', 'global', 'market', 'debilit', 'impact', 'intern', 'sanction', 'inva', 'ukrain', 'coupl', 'drop', 'price', 'persuad', 'vladimir', 'putin', 'govern', 'focus', 'foreign', 'debt', 'save', 'profit', 'seal', 'foreign', 'pressur', 'russian', 'financ', 'solid', 'rubl', 'unlik', 'petro', 'currenc', 'longer', 'whipsaw', 'price', 'serendipit', 'insul', 'global', 'market', 'prove', 'valuabl', 'time', 'half', 'countri', 'world', 'go', 'financ', 'help', 'surviv', 'pandem', 'thank', 'legaci', 'soviet', 'scienc', 'appli', 'technolog', 'russia', 'reason', 'advanc', 'digit', 'economi', 'produc', 'domest', 'internet', 'compani', 'potenti', 'withstand', 'challeng', 'american', 'chin', 'giant', 'tell', 'come', 'case', 'includ', 'countri', 'differ', 'russia', 'germani', 'list', 'thrive', 'economi', 'need', 'strong', 'defen', 'pressur', 'deglobali', 'debt', 'meddl', 'govern', 'coupl', 'offen', 'capabl', 'exploit', 'opportun', 'boom', 'digit', 'economi', 'veri', 'differ', 'degr', 'nation', 'opposit', 'histori', 'share', 'strength', 'futur', 'good', 'shoot', 'thrive', 'difficult', 'post', 'pandem', 'world']]\n"
     ]
    }
   ],
   "source": [
    "print(processed_docs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(9287 unique tokens: ['affair', 'break', 'busi', 'check', 'cover']...)\n"
     ]
    }
   ],
   "source": [
    "print (dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 affair\n",
      "1 break\n",
      "2 busi\n",
      "3 check\n",
      "4 cover\n",
      "5 current\n",
      "6 debat\n",
      "7 educ\n",
      "8 event\n",
      "9 happen\n",
      "10 india\n",
      "11 latest\n",
      "12 news\n",
      "13 on\n",
      "14 polit\n",
      "15 ring\n",
      "16 scienc\n",
      "17 stay\n",
      "18 stori\n",
      "19 time\n",
      "20 topic\n"
     ]
    }
   ],
   "source": [
    "#Lets see if dictionary created succesfully\n",
    "count=0\n",
    "for k,v in dictionary.iteritems():\n",
    "    print (k, v)\n",
    "    count +=1\n",
    "    if count >20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove rare and repeatative words\n",
    "dictionary.filter_extremes(no_below=15,no_above=0.1,keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(432 unique tokens: ['check', 'cover', 'educ', 'latest', 'polit']...)\n"
     ]
    }
   ],
   "source": [
    "print (dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the Bag-of-words model for each document i.e for each document we create a dictionary reporting how many\n",
    "#words and how many times those words appear. Save this to 'bow_corpus'\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 2), (5, 1), (6, 1), (7, 1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 8 (\"attempt\") appears 1 time.\n",
      "Word 10 (\"billion\") appears 1 time.\n",
      "Word 11 (\"book\") appears 1 time.\n",
      "Word 12 (\"communiti\") appears 1 time.\n",
      "Word 17 (\"explain\") appears 1 time.\n",
      "Word 25 (\"individu\") appears 1 time.\n",
      "Word 33 (\"network\") appears 2 time.\n",
      "Word 40 (\"pressur\") appears 1 time.\n",
      "Word 62 (\"address\") appears 1 time.\n",
      "Word 66 (\"collect\") appears 1 time.\n",
      "Word 74 (\"dream\") appears 1 time.\n",
      "Word 75 (\"effect\") appears 1 time.\n",
      "Word 81 (\"invest\") appears 1 time.\n",
      "Word 90 (\"privat\") appears 3 time.\n",
      "Word 97 (\"statement\") appears 1 time.\n",
      "Word 101 (\"advanc\") appears 2 time.\n",
      "Word 113 (\"econom\") appears 2 time.\n",
      "Word 116 (\"emerg\") appears 1 time.\n",
      "Word 133 (\"matter\") appears 1 time.\n",
      "Word 139 (\"potenti\") appears 2 time.\n",
      "Word 140 (\"prove\") appears 1 time.\n",
      "Word 143 (\"relat\") appears 1 time.\n",
      "Word 155 (\"small\") appears 2 time.\n",
      "Word 157 (\"spend\") appears 1 time.\n",
      "Word 161 (\"surpri\") appears 1 time.\n",
      "Word 168 (\"activ\") appears 3 time.\n",
      "Word 176 (\"parti\") appears 7 time.\n",
      "Word 188 (\"firm\") appears 1 time.\n",
      "Word 196 (\"promi\") appears 1 time.\n",
      "Word 205 (\"direct\") appears 3 time.\n",
      "Word 207 (\"feder\") appears 1 time.\n",
      "Word 227 (\"sen\") appears 1 time.\n",
      "Word 229 (\"suggest\") appears 2 time.\n",
      "Word 243 (\"integr\") appears 1 time.\n",
      "Word 254 (\"chairman\") appears 1 time.\n",
      "Word 255 (\"confer\") appears 2 time.\n",
      "Word 256 (\"director\") appears 1 time.\n",
      "Word 257 (\"encourag\") appears 1 time.\n",
      "Word 258 (\"energi\") appears 1 time.\n",
      "Word 259 (\"expand\") appears 2 time.\n",
      "Word 260 (\"involv\") appears 1 time.\n",
      "Word 261 (\"juli\") appears 1 time.\n",
      "Word 262 (\"refer\") appears 1 time.\n",
      "Word 263 (\"reveal\") appears 1 time.\n",
      "Word 264 (\"role\") appears 2 time.\n",
      "Word 265 (\"sector\") appears 1 time.\n",
      "Word 266 (\"stake\") appears 1 time.\n",
      "Word 267 (\"transmiss\") appears 1 time.\n",
      "Word 268 (\"user\") appears 2 time.\n"
     ]
    }
   ],
   "source": [
    "#preview \n",
    "document_num = 10\n",
    "bow_doc_x = bow_corpus[document_num]\n",
    "\n",
    "for i in range(len(bow_doc_x)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_x[i][0], \n",
    "                                                     dictionary[bow_doc_x[i][0]],\n",
    "                                                     bow_doc_x[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
    "                                   num_topics = 10, \n",
    "                                   id2word = dictionary,                                    \n",
    "                                   passes = 10,\n",
    "                                   workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.042*\"cricket\" + 0.023*\"coach\" + 0.018*\"dream\" + 0.018*\"tournament\" + 0.016*\"grand\" + 0.014*\"score\" + 0.013*\"young\" + 0.012*\"england\" + 0.012*\"court\" + 0.011*\"titl\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.025*\"footbal\" + 0.019*\"invest\" + 0.016*\"owner\" + 0.016*\"premier\" + 0.016*\"english\" + 0.014*\"success\" + 0.014*\"health\" + 0.012*\"titl\" + 0.012*\"money\" + 0.011*\"spend\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.040*\"lakh\" + 0.036*\"tour\" + 0.024*\"hyundai\" + 0.023*\"segment\" + 0.022*\"option\" + 0.022*\"photo\" + 0.021*\"variant\" + 0.020*\"latest\" + 0.019*\"movi\" + 0.016*\"transmiss\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.017*\"human\" + 0.017*\"court\" + 0.015*\"virus\" + 0.013*\"fear\" + 0.012*\"action\" + 0.012*\"connect\" + 0.011*\"emerg\" + 0.011*\"lockdown\" + 0.011*\"small\" + 0.010*\"self\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.047*\"cent\" + 0.043*\"demand\" + 0.042*\"delhi\" + 0.025*\"polici\" + 0.023*\"sector\" + 0.020*\"sale\" + 0.019*\"manufactur\" + 0.016*\"infrastructur\" + 0.016*\"august\" + 0.015*\"improv\"\n",
      "\n",
      "\n",
      "Topic: 5 \n",
      "Words: 0.027*\"road\" + 0.022*\"juli\" + 0.018*\"minist\" + 0.018*\"parti\" + 0.017*\"transport\" + 0.016*\"plant\" + 0.014*\"sourc\" + 0.014*\"ministri\" + 0.013*\"sale\" + 0.013*\"member\"\n",
      "\n",
      "\n",
      "Topic: 6 \n",
      "Words: 0.051*\"march\" + 0.047*\"januari\" + 0.038*\"race\" + 0.038*\"sunday\" + 0.031*\"photo\" + 0.029*\"compet\" + 0.028*\"championship\" + 0.025*\"victori\" + 0.022*\"score\" + 0.017*\"wednesday\"\n",
      "\n",
      "\n",
      "Topic: 7 \n",
      "Words: 0.055*\"women\" + 0.042*\"region\" + 0.024*\"august\" + 0.020*\"meet\" + 0.017*\"econom\" + 0.016*\"minist\" + 0.015*\"young\" + 0.014*\"polit\" + 0.013*\"join\" + 0.012*\"union\"\n",
      "\n",
      "\n",
      "Topic: 8 \n",
      "Words: 0.049*\"footbal\" + 0.040*\"photo\" + 0.027*\"athlet\" + 0.017*\"women\" + 0.016*\"school\" + 0.014*\"field\" + 0.013*\"refer\" + 0.012*\"univ\" + 0.012*\"profess\" + 0.012*\"receiv\"\n",
      "\n",
      "\n",
      "Topic: 9 \n",
      "Words: 0.097*\"februari\" + 0.031*\"word\" + 0.031*\"deal\" + 0.019*\"economi\" + 0.019*\"digit\" + 0.018*\"user\" + 0.014*\"educ\" + 0.013*\"enabl\" + 0.011*\"servic\" + 0.010*\"fight\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics():\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.3026955564121304),\n",
      " (1, 0.33283839242555835),\n",
      " (2, 0.34747123238377764),\n",
      " (3, 0.2787530139522639),\n",
      " (4, 0.5850460891378325),\n",
      " (5, 0.28775053967256903),\n",
      " (6, 0.29252304456891626),\n",
      " (7, 0.29749869484243646)]\n",
      "Topic: 0 Word: 0.021*\"food\" + 0.014*\"sure\" + 0.011*\"invest\" + 0.011*\"debut\" + 0.010*\"hous\" + 0.010*\"movi\" + 0.009*\"money\" + 0.009*\"grind\" + 0.009*\"learn\" + 0.009*\"excit\"\n",
      "Topic: 1 Word: 0.026*\"februari\" + 0.020*\"januari\" + 0.012*\"sunday\" + 0.011*\"ride\" + 0.009*\"train\" + 0.009*\"photo\" + 0.008*\"championship\" + 0.008*\"black\" + 0.008*\"england\" + 0.007*\"rate\"\n",
      "Topic: 2 Word: 0.016*\"cent\" + 0.014*\"sale\" + 0.012*\"word\" + 0.011*\"premium\" + 0.010*\"custom\" + 0.010*\"mind\" + 0.010*\"wear\" + 0.010*\"free\" + 0.009*\"segment\" + 0.008*\"explain\"\n",
      "Topic: 3 Word: 0.042*\"choic\" + 0.019*\"websit\" + 0.015*\"ensur\" + 0.015*\"cricket\" + 0.011*\"european\" + 0.011*\"dream\" + 0.011*\"arriv\" + 0.010*\"review\" + 0.010*\"union\" + 0.009*\"plea\"\n",
      "Topic: 4 Word: 0.011*\"race\" + 0.011*\"victori\" + 0.010*\"tour\" + 0.010*\"black\" + 0.010*\"premier\" + 0.009*\"delhi\" + 0.009*\"winner\" + 0.009*\"version\" + 0.008*\"teammat\" + 0.008*\"rest\"\n",
      "Topic: 5 Word: 0.014*\"minist\" + 0.012*\"human\" + 0.010*\"health\" + 0.010*\"region\" + 0.008*\"athlet\" + 0.008*\"london\" + 0.007*\"polici\" + 0.007*\"twitter\" + 0.007*\"polit\" + 0.007*\"sign\"\n",
      "Topic: 6 Word: 0.010*\"catch\" + 0.009*\"fee\" + 0.009*\"park\" + 0.009*\"consid\" + 0.009*\"space\" + 0.009*\"england\" + 0.008*\"sustain\" + 0.008*\"mile\" + 0.008*\"project\" + 0.008*\"reveal\"\n",
      "Topic: 7 Word: 0.016*\"footbal\" + 0.013*\"deal\" + 0.012*\"ring\" + 0.009*\"polit\" + 0.009*\"york\" + 0.008*\"relea\" + 0.008*\"cricket\" + 0.007*\"invest\" + 0.007*\"consum\" + 0.007*\"refer\"\n",
      "Topic: 8 Word: 0.014*\"cricket\" + 0.008*\"cost\" + 0.008*\"photo\" + 0.007*\"manufactur\" + 0.007*\"project\" + 0.007*\"march\" + 0.007*\"score\" + 0.007*\"school\" + 0.007*\"connect\" + 0.007*\"turn\"\n",
      "Topic: 9 Word: 0.022*\"movi\" + 0.020*\"lakh\" + 0.020*\"latest\" + 0.016*\"cast\" + 0.014*\"relea\" + 0.012*\"variant\" + 0.011*\"hyundai\" + 0.011*\"court\" + 0.010*\"option\" + 0.010*\"highlight\"\n"
     ]
    }
   ],
   "source": [
    "#LDA using TF-IDF\n",
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break\n",
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.3784719705581665\t \n",
      "Topic: 0.014*\"minist\" + 0.012*\"human\" + 0.010*\"health\" + 0.010*\"region\" + 0.008*\"athlet\" + 0.008*\"london\" + 0.007*\"polici\" + 0.007*\"twitter\" + 0.007*\"polit\" + 0.007*\"sign\"\n",
      "\n",
      "Score: 0.17108547687530518\t \n",
      "Topic: 0.042*\"choic\" + 0.019*\"websit\" + 0.015*\"ensur\" + 0.015*\"cricket\" + 0.011*\"european\" + 0.011*\"dream\" + 0.011*\"arriv\" + 0.010*\"review\" + 0.010*\"union\" + 0.009*\"plea\"\n",
      "\n",
      "Score: 0.14408209919929504\t \n",
      "Topic: 0.014*\"cricket\" + 0.008*\"cost\" + 0.008*\"photo\" + 0.007*\"manufactur\" + 0.007*\"project\" + 0.007*\"march\" + 0.007*\"score\" + 0.007*\"school\" + 0.007*\"connect\" + 0.007*\"turn\"\n",
      "\n",
      "Score: 0.12701639533042908\t \n",
      "Topic: 0.011*\"race\" + 0.011*\"victori\" + 0.010*\"tour\" + 0.010*\"black\" + 0.010*\"premier\" + 0.009*\"delhi\" + 0.009*\"winner\" + 0.009*\"version\" + 0.008*\"teammat\" + 0.008*\"rest\"\n",
      "\n",
      "Score: 0.10376241058111191\t \n",
      "Topic: 0.016*\"footbal\" + 0.013*\"deal\" + 0.012*\"ring\" + 0.009*\"polit\" + 0.009*\"york\" + 0.008*\"relea\" + 0.008*\"cricket\" + 0.007*\"invest\" + 0.007*\"consum\" + 0.007*\"refer\"\n",
      "\n",
      "Score: 0.053101684898138046\t \n",
      "Topic: 0.026*\"februari\" + 0.020*\"januari\" + 0.012*\"sunday\" + 0.011*\"ride\" + 0.009*\"train\" + 0.009*\"photo\" + 0.008*\"championship\" + 0.008*\"black\" + 0.008*\"england\" + 0.007*\"rate\"\n",
      "\n",
      "Score: 0.021396469324827194\t \n",
      "Topic: 0.022*\"movi\" + 0.020*\"lakh\" + 0.020*\"latest\" + 0.016*\"cast\" + 0.014*\"relea\" + 0.012*\"variant\" + 0.011*\"hyundai\" + 0.011*\"court\" + 0.010*\"option\" + 0.010*\"highlight\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model_tfidf[bow_corpus[250]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing model on unseen document\n",
    "unseen_document = 'One in five maple species is threatened in the wild, according to the first full assessment of extinction risks.Known for the vivid colour of their autumn leaves, the trees are popular in parks and gardens.But in their natural habitats, they face a myriad of threats, including unsustainable logging, climate change, deforestation and forest fires.Botanists are calling for urgent action to protect rare maple trees.And they say seeds should be stored as an insurance policy against extinction.The assessment of all 158 species of maple is part of an effort to map the conservation status of all tree species by the end of 2020. It was carried out by the group, Botanic Gardens Conservation International.Conservation manager Dan Crowley told BBC News:  Maples are some of our most familiar trees, particularly in autumn when they give us those wonderful displays of yellow, orange, red and purple colours.And whilst they are common in some of our open spaces, spaces where they are highly valued, several species are also highly threatened in the wild.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7803139686584473\t Topic: 0.017*\"human\" + 0.017*\"court\" + 0.015*\"virus\" + 0.013*\"fear\" + 0.012*\"action\"\n",
      "Score: 0.16252639889717102\t Topic: 0.049*\"footbal\" + 0.040*\"photo\" + 0.027*\"athlet\" + 0.017*\"women\" + 0.016*\"school\"\n"
     ]
    }
   ],
   "source": [
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
